{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4d4ded",
   "metadata": {},
   "source": [
    "### Levering MLflow for Experiment Tracking and Model Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab0c67",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The objective of this task is to introduce you to MLflow for experiment tracking, model management, and reproducibility in machine learning projects for the Sentiment Analysis Project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7de27",
   "metadata": {},
   "source": [
    "#### Incorporating MLflow into your machine learning project to showcase experiment monitoring, model administration, and reproducibility involves the following process:\n",
    "\n",
    "- Integrate MLflow into your existing machine learning projects.\n",
    "- Train machine learning models while logging relevant information with MLflow.\n",
    "- Demonstrate how to log parameters, metrics, and artifacts using MLflow tracking APIs.\n",
    "- Customizing MLflow UI with run names.\n",
    "- Demonstrate metric plots.\n",
    "- Demonstrate hyperparameter plots.\n",
    "- Demonstrate how to register models and manage by tagging them.\n",
    "- (BONUS) Build a Prefect Workflow and Auto Schedule it. Show the Prefect Dashboard with relevant outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cac3e",
   "metadata": {},
   "source": [
    "#### Load Data from the Dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0dee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\arsha\\Downloads\\reviews_data_dump\\reviews_badminton\\data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d8430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8518 entries, 0 to 8517\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8518 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# print properties of attributes in the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001d72cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of null values per column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4413549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784b7aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name      0\n",
       "Review Title       0\n",
       "Place of Review    0\n",
       "Up Votes           0\n",
       "Down Votes         0\n",
       "Month              0\n",
       "Review text        0\n",
       "Ratings            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4019b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8013 entries, 0 to 8507\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8013 non-null   object \n",
      " 1   Review Title     8013 non-null   object \n",
      " 2   Place of Review  8013 non-null   object \n",
      " 3   Up Votes         8013 non-null   float64\n",
      " 4   Down Votes       8013 non-null   float64\n",
      " 5   Month            8013 non-null   object \n",
      " 6   Review text      8013 non-null   object \n",
      " 7   Ratings          8013 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 563.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b32fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a sentiment column to classify reviews as Positive or Negative\n",
    "# Positive = 1\n",
    "# Negative = 0\n",
    "\n",
    "# Method 1: Using numpy's where function\n",
    "data['sentiment'] = np.where(data['Ratings'] == 5.0, 1,\n",
    "                              np.where(data['Ratings'] == 4.0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba86dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using pandas' map function\n",
    "# Create a dictionary mapping star ratings to sentiments\n",
    "rating_sentiment_map = {5.0: 1, 4.0: 1, 1.0: 0, 2.0: 0, 3.0: 0}\n",
    "\n",
    "# Map star ratings to sentiments using the dictionary\n",
    "data['sentiment'] = data['Ratings'].map(rating_sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e85d3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baji Sankar</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>173.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Oct 2018</td>\n",
       "      <td>Good quality product. Delivered on time.READ MORE</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Certified Buyer, Doom Dooma</td>\n",
       "      <td>403.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Jan 2020</td>\n",
       "      <td>BEST PURCHASE It is a good quality and is more...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "5             Baji Sankar      Mind-blowing purchase   \n",
       "6       Flipkart Customer                  Must buy!   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "5   Certified Buyer, Hyderabad     173.0        45.0  Oct 2018   \n",
       "6  Certified Buyer, Doom Dooma     403.0       121.0  Jan 2020   \n",
       "\n",
       "                                         Review text  Ratings  sentiment  \n",
       "0  Nice product, good quality, but price is now r...        4          1  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1          0  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1          0  \n",
       "5  Good quality product. Delivered on time.READ MORE        5          1  \n",
       "6  BEST PURCHASE It is a good quality and is more...        5          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c9649",
   "metadata": {},
   "source": [
    "#### Identify input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d460560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Review text\"]\n",
    "y = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbb0b6",
   "metadata": {},
   "source": [
    "#### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b4d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0568243-7f3f-4bef-bb35-7ab7064e70e6",
   "metadata": {},
   "source": [
    "#### Data Cleaning and preprocessing on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12f19d5-d95c-45eb-8ded-04ca638e0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Preprocessing functions\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb7814b4-2245-47d0-9cad-8969d6ac17bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6009,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply text cleaning to the X_train data\n",
    "X_train = X_train.apply(clean_text)\n",
    "X_train = X_train.apply(lemmatize_text)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb973798-c447-4cb6-826f-85ada123ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply text cleaning to the X_test data\n",
    "X_test = X_test.apply(clean_text)\n",
    "X_test = X_test.apply(lemmatize_text)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b29f7",
   "metadata": {},
   "source": [
    "#### Running the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e93cb7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in c:\\users\\arsha\\anaconda3\\lib\\site-packages (2.11.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.1.42)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (4.25.3)\n",
      "Requirement already satisfied: pytz<2025 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (2022.7)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (23.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (6.0.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (7.0.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.24.3)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.10.1)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.5.3)\n",
      "Requirement already satisfied: querystring-parser<2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.4.39)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.7.1)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.3)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (1.26.16)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (1.7.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\arsha\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bbb0c90-6175-47d0-9764-18d462bd5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48edceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    " mlflow.set_tracking_uri(\"sqlite:///mlflow_1.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b3902f-5522-44de-b952-62129638090c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/arsha/Downloads/MLOPs/mlruns/998641720780543424', creation_time=1711616665462, experiment_id='998641720780543424', last_update_time=1711616665462, lifecycle_stage='active', name='Sentiment Analysis of Flipkart Product Reviews', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# mlflow.set_tracking_uri(\"sqlite:///mlflow_1.db\")\n",
    "\n",
    "mlflow.set_experiment(\"Sentiment Analysis of Flipkart Product Reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf6300-6f76-4b9d-ab29-be572e02fce5",
   "metadata": {},
   "source": [
    "#### Auto Logging All Experiment Runs using MLFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17dc1fb1-c29f-4304-adc5-2750fd7f2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines for various classifiers\n",
    "pipelines = {\n",
    "    'knn': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'svc': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'random_forest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'knn': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__n_neighbors': [3, 5, 7],\n",
    "            'classifier__p': [1, 2, 3]\n",
    "        }\n",
    "    ],\n",
    "    'svc': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel': ['rbf'],\n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "        },\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel': ['linear'],\n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__penalty': ['l1', 'l2']\n",
    "        }\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b2e6e1-2bf2-4c18-b587-fb0393bcf765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** knn **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 14:47:47 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/03/28 14:47:47 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 5min 17s\n",
      "Wall time: 2min 7s\n",
      "Score on Test Data:  0.8637724550898204\n",
      "********** svc **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 14:49:55 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 1min 38s\n",
      "Wall time: 3min 17s\n",
      "Score on Test Data:  0.8822355289421158\n",
      "********** logistic_regression **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 14:53:13 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 9.59 s\n",
      "Wall time: 34 s\n",
      "Score on Test Data:  0.8812375249500998\n",
      "********** random_forest **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 14:53:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "CPU times: total: 5min 18s\n",
      "Wall time: 9min 34s\n",
      "Score on Test Data:  0.8822355289421158\n",
      "********** decision_tree **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 15:03:23 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "CPU times: total: 12.1 s\n",
      "Wall time: 45.2 s\n",
      "Score on Test Data:  0.8662674650698603\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for each algorithm\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "        \n",
    "    # print('Score on Train Data: ', grid_search.best_score_)\n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26503c78-e9c9-4c3d-bff5-ca9cddaa17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the auto logger\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4b0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:05:20 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a16fd7e1dea645b0a642d4a4208e7f65', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/28 19:05:20 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** knn **********\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:07:28 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.8597113331790895\n",
      "Test Score:  0.8637724550898204\n",
      "Fit Time:  127.97832441329956\n",
      "Predict Time:  0.3654301166534424\n",
      "Model Size:  425339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:07:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8d29c68b1986490b9101a706d47cdaef', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/28 19:07:29 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** svc **********\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:10:55 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.878681935879834\n",
      "Test Score:  0.8822355289421158\n",
      "Fit Time:  205.7623302936554\n",
      "Predict Time:  0.2769961357116699\n",
      "Model Size:  287437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:10:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9fc31f526ef849849724b6eca12948c8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/28 19:10:56 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:11:32 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.8740233111342324\n",
      "Test Score:  0.8812375249500998\n",
      "Fit Time:  36.02333188056946\n",
      "Predict Time:  0.0432741641998291\n",
      "Model Size:  120881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:11:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '344245e970eb49aaafd3f6db495e6f38', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/28 19:11:33 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** random_forest **********\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:23:02 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.8758531783691073\n",
      "Test Score:  0.8817365269461078\n",
      "Fit Time:  689.3061170578003\n",
      "Predict Time:  0.4957869052886963\n",
      "Model Size:  29732050\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:23:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6489e03ff7e8485c9868799aa67c99bf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/28 19:23:04 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 19:23:56 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.8577129984580237\n",
      "Test Score:  0.8682634730538922\n",
      "Fit Time:  52.3689227104187\n",
      "Predict Time:  0.049196720123291016\n",
      "Model Size:  71136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dev = \"MOHD ARSHAD\"\n",
    "best_models = {}\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "directory = 'C:/Users/arsha/Downloads/MLOPs/model/Best Models'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "\n",
    "    # Fit\n",
    "    start_fit_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_fit_time = time.time()\n",
    "\n",
    "    # Predict\n",
    "    start_predict_time = time.time()\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    end_predict_time = time.time()\n",
    "\n",
    "    # Saving the best model\n",
    "    model_path = f'C:/Users/arsha/Downloads/MLOPs/model/Best Models/{algo}.pkl'\n",
    "    joblib.dump(grid_search.best_estimator_, model_path)\n",
    "    model_size = os.path.getsize(model_path)\n",
    "\n",
    "    # Print Log\n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "    print(\"Fit Time: \", end_fit_time - start_fit_time)\n",
    "    print(\"Predict Time: \", end_predict_time - start_predict_time)\n",
    "    print(\"Model Size: \", model_size)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    # Start the experiment run\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log tags with mlflow.set_tag()\n",
    "        mlflow.set_tag(\"developer\", dev)\n",
    "\n",
    "        # Log Parameters with mlflow.log_param()\n",
    "        mlflow.log_param(\"algorithm\", algo)\n",
    "        mlflow.log_param(\"hyperparameter_grid\", param_grids[algo])\n",
    "        mlflow.log_param(\"best_hyperparameter\", grid_search.best_params_)\n",
    "\n",
    "        # Log Metrics with mlflow.log_metric()\n",
    "        mlflow.log_metric(\"train_score\", grid_search.best_score_)\n",
    "        mlflow.log_metric(\"test_score\", grid_search.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"fit_time\", end_fit_time - start_fit_time)\n",
    "        mlflow.log_metric(\"predict_time\", end_predict_time - start_predict_time)\n",
    "        mlflow.log_metric(\"model_size\", model_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89861982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
